---
title: "Data Support for Swedish Pharmacy Residents"
author: "Jack B. Huber, Ph.D."
date: "`r format(Sys.Date(), '%B %Y')`"
documentclass: report
bibliography: [bibfile.bib,packages.bib]
link-citations: yes
output:
  pdf_document:
    includes:
      in_header: preamble.tex
    latex_engine: xelatex
    citation_package: natbib
    keep_tex: yes
  prettydoc::html_pretty:
    theme: hpstr
  html_document:
    theme: cerulean
    toc: yes
    # number_sections: yes
    toc_float:
      collapsed: yes
      smooth_scroll: yes
    citation_package: natbib
    fig_caption: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

knitr::write_bib(c(.packages(),"knitr","VIM"),"packages.bib")
```

# Purpose of this Document
The purpose of this document is to assemble some advice and resources to support Swedish Pharmacy residents in their journey from project proposal to a completed research project.

# Planning your Project

## The causal logic of your project
Fundamentally, the resident research project is an effort to gather causal evidence for the claim that a particular treatment or way of utilizing medicine "worked" by being more effective than a rival or pre-existing treatment. To plan data collection for the strongest causal evidence is the purpose of research design [@CampbellStanley1963].

The ideal research design would be a pure experiment with random assignment. The resident would randomly assign patients to treatment and control conditions, then compare outcomes following treatment. In such a scenario the resident could attribute any significant difference in outcomes to the treatment because the groups would differ only by chance in all other ways. Any pre-existing differences would be statistically insignificant.

Because the resident cannot randomly assign patients to conditions going forward, the project falls under the category of _**quasi-experiment**_. This means it is more vulnerable to confounding explanations of any difference in outcomes.

The resident research project will culminate in a comparison between two groups: a pre-implementation group and a post-implementation group. One difference between the groups is time, and recent history has made a big difference. Compare a pre-implementation group from the onset of the pandemic with a high incidence of COVID-19 to a more recent post-implementation group with much lower incidence of the virus. This difference between the two groups in COVID-19 infection may combine with the difference in drug dosing to influence treatment outcomes. This difference in COVID-19 infection could therefore be a _**confound**_.

The point is to clarify:

- What is the outcome to improve? This is the dependent variable.
- What is the difference in treatment intended to cause the improvement in the post-implementation group? This is the independent variable.
- All other variables are control variables. They should differ only by chance. If there is a noticeable pre-existing difference, and the level of that factor in one group affects the outcome, it is a confound.

## How many patients?

Possibly the most pressing question for resident research projects is: How many patients do I need? The resident research project will culiminate in a series of comparisons between the pre-implementation and post-implementation groups. Outcomes of the two samples will differ by at least some quantity. The resident researcher expresses this difference as an effect, like this:

Assume that this effect suggests more favorable outcomes for the post-implementation group. This effect raises several questions:

- How do we evaluate this effect?
- Could we attribute it to chance? (because it would be very unlikely for both groups to have exactly the same outcomes)
- Or is it larger than that?

In statistical terms, this is a question of **statistical power**. Power is the ability to isolate a treatment effect when it really does exist [@Cohen1988]. Power is a function of effect size, sample size, and statistical significance. In order to decide on a number of patients we need to have a sense of what size of effect we want to reliably detect.

```{r power, echo=FALSE, fig.cap='Power Analysis'}
# Plot sample size curves for detecting correlations of
# various sizes.

library(pwr)

# range of correlations
r <- seq(.1,.5,.01)
nr <- length(r)

# power values
p <- seq(.4,.9,.1)
np <- length(p)

# obtain sample sizes
samsize <- array(numeric(nr*np), dim=c(nr,np))
for (i in 1:np){
  for (j in 1:nr){
    result <- pwr.r.test(n = NULL, r = r[j],
                         sig.level = .05, power = p[i],
                         alternative = "two.sided")
    samsize[j,i] <- ceiling(result$n)
  }
}

# set up graph
xrange <- range(r)
yrange <- round(range(samsize))
colors <- rainbow(length(p))
plot(xrange, yrange, type="n",
     xlab="Correlation Coefficient (r)",
     ylab="Sample Size (n)" )

# add power curves
for (i in 1:np){
  lines(r, samsize[,i], type="l", lwd=2, col=colors[i])
}

# add annotation (grid lines, title, legend)
abline(v=0, h=seq(0,yrange[2],50), lty=2, col="grey89")
abline(h=0, v=seq(xrange[1],xrange[2],.02), lty=2,
       col="grey89")
title("Sample Size Estimation for Correlation Studies\n
  Sig=0.05 (Two-tailed)")
legend("topright", title="Power", as.character(p),
       fill=colors)
```

Power is a function of sample size, effect size, and statistical significance. Figure \@ref(fig:power) is a plot of power rates against these other variables. A large effect (r ~ 0.5) is detectable with a sample of any size. But only large samples have the power to detect a statistically significant (p < .05) small correlation (r = 0.1). 

# Collecting your Data

## Data Sources

- Epic
- Cogito dashboards
- SlicerDicer
- Custom reporting (SQL)

## Granularity

- Patient-level data
- Encounter level data
- Medication administration level data
- Lab results level data

## Advice for Data Collection

1. Define the most critical variables.

2. Study an exemplar (provided).

3. We need to figure out version control. Data proliferation and overload. 

# Analyzing your Data
You have data. Congratulations! Let's analyze!


## Preparing your data for analysis
The first step is to complete a number of tasks to prepare your data for analysis. One data matrix. See the exemplar.

## Choosing appropriate statistics
It is important to know the measurement level of your variables. How do you express the outcome by which to compare your pre- and post- samples? Is it...

- Mortality rate (% surviving)? In such a case you would be comparing two proportions.
- "Time to..." a therapeutic level? In such a case you would be comparing two different quantities of time.

### Odds ratios

### Chi-square test of independence

### Two-sample t-test

### Z test of the difference of proportions

### Cohen's _d_ effect size

# Reporting your Results

## Advice on graphs

## Advice on tables

`r if (knitr::is_html_output()) '
# References {-}
'`
<div id="refs"></div>